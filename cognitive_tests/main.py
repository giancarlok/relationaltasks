import argparseimport osimport sysimport timeimport numpy as npfrom PIL import Imageimport torchimport torchvisionimport torch.nn as nnimport torch.optim as optimfrom torch.utils.data import Dataset, DataLoaderimport torch.nn.functional as F# Prevent python from saving out .pyc filessys.dont_write_bytecode = True# Add models and tasks to pathsys.path.insert(0, './models')sys.path.insert(0, './tasks')# Logging utilityfrom util import log# Method for creating directory if it doesn't exist yetdef check_path(path):	if not os.path.exists(path):		os.mkdir(path)class seq_dataset(Dataset):	def __init__(self, dset, args):		self.seq_ind = dset['seq_ind']		self.y = dset['y']		self.len = self.seq_ind.shape[0]	def __len__(self):		return self.len	def __getitem__(self, idx):		seq_ind = self.seq_ind[idx]		y = self.y[idx]		return seq_ind, ydef train(args, model, device, optimizer, iter, x_train, y_train):	# Create file for saving training progress	check_path('./results/')	train_prog_dir = './results/train_prog/'	check_path(train_prog_dir)	if args.hard:		task_dir = train_prog_dir + args.task + '_hard/'	elif args.tricky:		task_dir = train_prog_dir + args.task + '_tricky'+str(args.sampling_weight)+'/'	elif args.colour_tested:		task_dir = train_prog_dir + args.task + '_colour_tested' + '/'	elif args.shape_tested:		task_dir = train_prog_dir + args.task + '_shape_tested' + '/'	else:		task_dir = train_prog_dir + args.task + '/'	check_path(task_dir)	shapes_gen_dir = task_dir + 'n' + str(args.n_shapes) + '/'	check_path(shapes_gen_dir)	gen_dir = shapes_gen_dir + 'm' + str(args.m_holdout) + '/'	check_path(gen_dir)	model_dir = gen_dir + args.model_name + '/'	check_path(model_dir)	run_dir = model_dir + 'run' + args.run + '/'	check_path(run_dir)	# Set to training mode 	model.train()	# Iterate over batches	# Batch start time	start_time = time.time()	#print("seq_ind", seq_ind.shape)	# Use sequence indices to slice corresponding images	x_seq = torch.Tensor(x_train)	#x_seq = x_seq[:,:,0]	y = torch.Tensor(y_train).long()	#print("x_seq", x_seq.shape)	# Load data to device	x_seq = x_seq.to(device)	y = y.to(device)	# Zero out gradients for optimizer	optimizer.zero_grad()	# Run model	if "_l1" in args.model_name:		y_pred_linear, y_pred, R_save, l1_penalty = model(x_seq, device)		loss_fn = nn.CrossEntropyLoss()		loss = loss_fn(y_pred_linear, y)+ args.l1_lambda*l1_penalty	elif 'MNM' in args.model_name:		y_pred_linear, y_pred, const_loss, R_save = model(x_seq, device)		loss_fn = nn.CrossEntropyLoss()		loss = loss_fn(y_pred_linear, y)		loss += const_loss	else:		y_pred_linear, y_pred, R_save = model(x_seq, device)		loss_fn = nn.CrossEntropyLoss()		loss = loss_fn(y_pred_linear, y)	# Update model	loss.backward()	optimizer.step()	# Batch duration	end_time = time.time()	batch_dur = end_time - start_time	# Report prgoress	acc = torch.eq(y_pred, y).float().mean().item() * 100.0	if iter % 100 == 0:		# Report		train_prog_fname = run_dir + 'iter_' + str(iter) + '.txt'		train_prog_f = open(train_prog_fname, 'w')		train_prog_f.write('batch loss acc\n')		log.info('[Iter: ' + str(iter) + '] ' + \				 '[Loss = ' + '{:.4f}'.format(loss.item()) + '] ' + \				 '[Accuracy = ' + '{:.2f}'.format(acc) + '] ' + \				 '[' + '{:.3f}'.format(batch_dur) + ' sec/batch]')		# Save progress to file		train_prog_f.write(str(iter) + ' ' +\						   '{:.4f}'.format(loss.item()) + ' ' + \						   '{:.2f}'.format(acc) + '\n')		train_prog_f.close()def test(args, model, device, task_gen, all_imgs, all_colours, test_shapes):	log.info('Evaluating on test set...')	# Set to eval mode	model.eval()	# Iterate over batches	all_acc = []	all_loss = []	with torch.no_grad():		for batch_idx in range(1000):			# Use sequence indices to slice corresponding images			prob = [0.5,0.5]			if args.hard:				x_train, y_train = task_gen.get_hard_sample(args.test_batch_size, prob, all_imgs[test_shapes])			elif args.tricky:				x_train, y_train = task_gen.get_tricky_sample(args.test_batch_size, prob, all_imgs[test_shapes], all_colours, 1-args.sampling_weight)			elif args.colour_tested:				#print("colour_tested")				x_train, y_train = task_gen.get_coloured_sample(args.test_batch_size, prob, all_imgs[test_shapes], all_colours)			elif args.shape_tested:				#print("colour_tested")				x_train, y_train = task_gen.get_shapes_sample(args.test_batch_size, prob, all_imgs[test_shapes], all_colours)			elif "identity_rules4_" in args.task or "_hard" in args.task:				x_train, y_train = task_gen.get_test_sample(args.test_batch_size, prob, all_imgs[test_shapes],															  all_colours)			else:				x_train, y_train = task_gen.get_sample(args.test_batch_size, prob, all_imgs[test_shapes], all_colours)			# Load data to device			x_seq = torch.Tensor(x_train)			#x_seq = x_seq[:, :, 0]			y = torch.Tensor(y_train).long()			x_seq = x_seq.to(device)			y = y.to(device)			# Run model			if "_l1" in args.model_name:				y_pred_linear, y_pred, R_save, l1_penalty = model(x_seq, device)			elif 'MNM' in args.model_name:				y_pred_linear, y_pred, const_loss, R_save = model(x_seq, device)			else:				y_pred_linear, y_pred, R_save = model(x_seq, device)			#print(R_save.shape)			if args.saving_image:				img_dir =  './matrix_images/'				check_path(img_dir)				img_task_dir = img_dir + args.task + '/'				check_path(img_task_dir)				img_gen_dir = img_task_dir + 'm' + str(args.m_holdout) + '/'				check_path(img_gen_dir)				img_model_dir = img_gen_dir + "/" +args.model_name+ "/"				check_path(img_model_dir)				# print(y.shape)				# print("hello", y_pred.shape)				error_image = torch.abs(y-y_pred).view(y.shape[0], 1,1,1)*torch.ones_like(x_seq[0])				print(y.shape)				print(y.type)				print(x_seq[0])				y_img = torch.abs(y).view(y.shape[0], 1,1,1)*torch.ones_like(x_seq[0])				print(y_img.shape)				print(y_img.type)				y_pred_img = torch.abs(y).view(y.shape[0], 1, 1, 1) * torch.ones_like(x_seq[0])				torchvision.utils.save_image(y_img, img_model_dir+"y_img.png")				torchvision.utils.save_image(y_pred_img, img_model_dir+"y_pred_img.png")				torchvision.utils.save_image(error_image, img_model_dir+"error.png")				# print("x_Seq", x_seq.shape)				# print("shape ", x_seq.shape[-3:])				# print(R_save.shape)				if args.task == "same_diff":					icons = torch.cat([x_seq[:,0].unsqueeze(1), x_seq[:,1].unsqueeze(1)], dim=-1)				elif args.task == "RMTS":					row1 = torch.cat([x_seq[:,0].unsqueeze(1), x_seq[:,1].unsqueeze(1), torch.zeros(x_seq[:,0].shape).unsqueeze(1), torch.zeros(x_seq[:,0].shape).unsqueeze(1)], dim=-1)					row2 = torch.cat([x_seq[:,2].unsqueeze(1), x_seq[:,3].unsqueeze(1), x_seq[:,4].unsqueeze(1), x_seq[:,5].unsqueeze(1)], dim=-1)					print(row1.shape)					print(row2.shape)					icons = torch.cat([row1, row2], dim=-2)				else:					icons = x_seq[:, 0].unsqueeze(1)					for k in range(1, 9):						icons = torch.cat([icons, x_seq[:, k].unsqueeze(1)], dim=-1)				torchvision.utils.save_image(icons, img_model_dir+"image.png", padding = 8)				if R_save is not None:					R_save = nn.Upsample(scale_factor = x_seq.shape[-2:])(R_save.unsqueeze(1))					torchvision.utils.save_image(R_save, img_model_dir+"matrix.png", padding = 16)			# Loss			loss_fn = nn.CrossEntropyLoss()			loss = loss_fn(y_pred_linear, y)			if 'MNM' in args.model_name:				loss += const_loss			all_loss.append(loss.item())			# Accuracy			acc = torch.eq(y_pred, y).float().mean().item() * 100.0			all_acc.append(acc)		# Report progress	# Report overall test performance	avg_loss = np.mean(all_loss)	avg_acc = np.mean(all_acc)	log.info('[Summary] ' + \			 '[Loss = ' + '{:.4f}'.format(avg_loss) + '] ' + \			 '[Accuracy = ' + '{:.2f}'.format(avg_acc) + ']')	# Save performance	test_dir = './results/test/'	check_path(test_dir)	if args.hard:		task_dir = test_dir + args.task + '_hard/'	elif args.tricky:		task_dir = test_dir + args.task +'_tricky' + str(args.sampling_weight) + '/'	elif args.colour_tested:		task_dir = test_dir + args.task + '_colour_tested' + '/'	elif args.shape_tested:		task_dir = test_dir + args.task + '_shape_tested' + '/'	else:		task_dir = test_dir + args.task + '/'	check_path(task_dir)	shapes_gen_dir = task_dir + 'n' + str(args.n_shapes) + '/'	check_path(shapes_gen_dir)	gen_dir = shapes_gen_dir + 'm' + str(args.m_holdout) + '/'	check_path(gen_dir)	model_dir = gen_dir + args.model_name + '/'	check_path(model_dir)	test_fname = model_dir + 'run' + args.run + '.txt'	test_f = open(test_fname, 'w')	test_f.write('loss acc\n')	test_f.write('{:.4f}'.format(avg_loss) + ' ' + \				 '{:.2f}'.format(avg_acc))	test_f.close()def main():	# Settings	parser = argparse.ArgumentParser()	# Model settings	parser.add_argument('--model_name', type=str, default='ESBN', help="{'ESBN', 'Transformer', 'NTM', 'LSTM', 'PrediNet', 'RN', 'MNM', 'TRN', 'ESBN_confidence_ablation', 'ESBN_default_memory', 'tsf', 'rule_tsf', 'ni_tsf'}")	parser.add_argument('--norm_type', type=str, default='contextnorm', help="{'nonorm', 'contextnorm', 'tasksegmented_contextnorm'}")	parser.add_argument('--encoder', type=str, default='conv', help="{'conv', 'mlp', 'rand'}")	parser.add_argument('--l1_lambda', type=float, default=0.001)	# Transformer Based Model Settings	parser.add_argument('--heads', type=int, default=8)	parser.add_argument('--rules', type=int, default=1)	parser.add_argument('--layers', type=int, default=1)	parser.add_argument('--freeze_encoder', action='store_true', default=False)	parser.add_argument('--norm_before', action='store_true', default=False)	parser.add_argument('--residual', action='store_true', default=False)	parser.add_argument('--sqrt', action='store_true', default=False)	parser.add_argument('--gumbel', action='store_true', default=False)	parser.add_argument('--colour_tested', action='store_true', default=False)	parser.add_argument('--shape_tested', action='store_true', default=False)	parser.add_argument('--normalized', action='store_true', default=False)	parser.add_argument('--detached', action='store_true', default=False)	parser.add_argument('--saving_image', action='store_true', default=False)	parser.add_argument('--no_adding', action='store_true', default=False)	parser.add_argument('--no_positional', action='store_true', default=False)	parser.add_argument('--hard', action='store_true', default=False)	parser.add_argument('--tricky', action='store_true', default=False)	parser.add_argument('--sampling_weight', type=float, default=0.1)	parser.add_argument('--reduced', action='store_true', default=False)	parser.add_argument('--use_sigmoid', action='store_true', default=False)	parser.add_argument('--use_rnn', action='store_true', default=False)	parser.add_argument('--no_masking', action='store_true', default=False)	parser.add_argument('--conf_abs', action='store_true', default=False)	parser.add_argument('--conf_sigmoid', action='store_true', default=False)	parser.add_argument('--concat_after', action='store_true', default=False)	parser.add_argument('--key_dim', type=int, default=256,						help="dimension of abstract keys")	parser.add_argument('--query_dim', type=int, default=8,						help="dimension of abstract keys")	parser.add_argument('--value_dim', type=int, default=256,						help="dimension of abstract keys")	parser.add_argument('--pos_dim', type=int, default=8,						help="dimension of abstract keys")	parser.add_argument('--tsf_dim', type=int, default=512,						help="dimension of abstract keys")	parser.add_argument('--selfattention', action='store_true', default=False)	parser.add_argument('--separate', action='store_true', default=False)	# Task settings	parser.add_argument('--task', type=str, default='same_diff', help="{'same_diff', 'RMTS', 'dist3', 'identity_rules'}")	parser.add_argument('--train_gen_method', type=str, default='full_space', help="{'full_space', 'subsample'}")	parser.add_argument('--test_gen_method', type=str, default='full_space', help="{'full_space', 'subsample'}")	parser.add_argument('--n_colours', type=int, default=100, help="n = total number of colours available for training and testing")	parser.add_argument('--n_shapes', type=int, default=100, help="n = total number of shapes available for training and testing")	parser.add_argument('--m_holdout', type=int, default=0, help="m = number of objects (out of n) withheld during training")	parser.add_argument('--c_holdout', type=int, default=0, help="m = number of objects (out of n) withheld during training")	# Training settings	parser.add_argument('--train_batch_size', type=int, default=32)	parser.add_argument('--train_set_size', type=int, default=10000)	parser.add_argument('--train_proportion', type=float, default=0.95)	parser.add_argument('--lr', type=float, default=5e-4)	parser.add_argument('--iterations', type=int, default=5000)	parser.add_argument('--log_interval', type=int, default=10)	# Test settings	parser.add_argument('--test_batch_size', type=int, default=1000)	parser.add_argument('--test_set_size', type=int, default=10000)	# Device settings	parser.add_argument('--no-cuda', action='store_true', default=False)	parser.add_argument('--device', type=int, default=0)	# Run number	parser.add_argument('--run', type=str, default='1')	args = parser.parse_args()	# TSF parameters	args.key_dim = args.tsf_dim	args.value_dim = args.tsf_dim	if "CoRelNet" in args.model_name:		args.selfattention = True		args.reduced = True		args.no_adding = True	if "CoRelNet_qtsf" in args.model_name:		args.sqrt = True		args.residual = True	# Set up cuda	use_cuda = not args.no_cuda and torch.cuda.is_available()	device = torch.device("cuda:" + str(args.device) if use_cuda else "cpu")	kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}	# Randomly assign objects to training or test set	all_shapes = np.arange(args.n_shapes)	np.random.shuffle(all_shapes)	if args.m_holdout > 0:		train_shapes = all_shapes[args.m_holdout:]		test_shapes = all_shapes[:args.m_holdout]	else:		train_shapes = all_shapes		test_shapes = all_shapes	all_colour_indices = np.arange(args.n_colours)	np.random.shuffle(all_colour_indices)	if args.c_holdout > 0:		train_colours = all_colour_indices[args.c_holdout:]		test_colours = all_colour_indices[:args.c_holdout]	else:		train_colours = all_colour_indices		test_colours = all_colour_indices	# Generate training and test sets	task_gen = __import__(args.task)	log.info('Generating task: ' + args.task + '...')	print("args task ", args.task)	print("task_gen", task_gen)	print("y_dim", task_gen.y_dim)	# Load images	# all_imgs = []	# for i in range(args.n_shapes):	# 	img_fname = './imgs/' + str(i) + '.png'	# 	img = torch.Tensor(np.array(Image.open(img_fname))) / 255.	# 	all_imgs.append(img)	# all_imgs = torch.stack(all_imgs, 0)	all_imgs = []	for i in range(100):		img_fname = './imgs/' + str(i) + '.png'		img = torch.Tensor(np.array(Image.open(img_fname))) / 255.		img = img.repeat(1, 3, 1, 1)		#img = (img >= 0.5).float()		all_imgs.append(img)	all_imgs = torch.stack(all_imgs, 0)[:, 0]	rng = np.random.RandomState(0)	all_colours = rng.uniform(size=(args.n_colours, 3, 1, 1))	#all_colours = np.ones(shape=(100,3,1,1))	all_colours = torch.Tensor(all_colours).repeat(1, 1, 32, 32).numpy()	if args.task == "same_diff_sep_shapes" or args.task == "same_diff_sep_colours":		all_colours = torch.Tensor(all_colours)		all_imgs = F.interpolate(all_imgs, size=(32, 16))		all_colours = F.interpolate(all_colours, size=(32, 16))	print("train_shapes", train_shapes.shape)	print("test_shapes", test_shapes.shape)	print("all_imgs", all_imgs.shape)	print("all_imgs", all_colours.shape)	print("all_imgs[train_shapes,:,:,:]", all_imgs[train_shapes, :, :, :].shape)	print("all_imgs[test_shapes]", all_imgs[test_shapes].shape)	print("all_colours[train_colours,:,:,:]", all_colours[train_colours, :, :, :].shape)	print("all_colours[test_colours]", all_colours[test_colours].shape)	#exit()	# Create model	model_class = __import__(args.model_name)	model = model_class.Model(task_gen, args).to(device)	# Append relevant hyperparameter values to model name	if 'tsf' in args.model_name:		args.model_name = args.model_name + '-heads-' + str(args.heads) + '-layers-' + str(args.layers) + '-dim-' + str(args.tsf_dim)+ '-pos_dim-' + str(args.pos_dim)		if 'qtsf' in args.model_name:			args.model_name = args.model_name +'-qdim-' + str(args.query_dim)	elif args.model_name == 'rule_tsf' or args.model_name == 'ni_tsf':		args.model_name = args.model_name + '-heads-' + str(args.heads) + '-rules-' + str(args.rules) + '-layers-' + str(args.layers)	if '_l1' in args.model_name:		args.model_name = args.model_name + '-lambda-' + str(args.l1_lambda)	if args.separate and 'tsf' in args.model_name:		args.model_name = args.model_name + '-separate'	if args.gumbel and ('rule' in args.model_name or 'ni' in args.model_name):		args.model_name = args.model_name + '-gumbel'	if args.selfattention:		args.model_name = args.model_name + '-selfattention'		if args.no_adding:			args.model_name = args.model_name + '-noadding'		if args.no_masking:			args.model_name = args.model_name + '-nomasking'		elif args.reduced:			args.model_name = args.model_name + '-reduced'	if args.normalized:		args.model_name = args.model_name + '-normalized'		if args.detached:			args.model_name = args.model_name + '-detached'	if args.no_positional:		args.model_name = args.model_name + '-no_positional'	if args.residual:		args.model_name = args.model_name + '-residual'	if args.sqrt:		args.model_name = args.model_name + '-sqrt'	if args.norm_before:		args.model_name = args.model_name + '-norm_before'	if args.freeze_encoder:		args.model_name = args.model_name + '-freeze_encoder'	args.model_name = args.model_name + '_' + args.norm_type + '_lr' + str(args.lr)	# Create optimizer	log.info('Setting up optimizer...')	optimizer = optim.Adam(model.parameters(), lr=args.lr)	# Train	log.info('Training begins...')	for iter in range(1, args.iterations + 1):		# Training loop		prob = [0.5, 0.5]		if args.tricky:			x_train, y_train = task_gen.get_tricky_sample(args.train_batch_size, prob, all_imgs[train_shapes, :, :, :], all_colours[train_colours, :, :, :], args.sampling_weight)		else:			x_train, y_train = task_gen.get_sample(args.train_batch_size, prob, all_imgs[train_shapes,:,:,:], all_colours[train_colours, :, :, :])		train(args, model, device, optimizer, iter, x_train, y_train)	# Test model	test(args, model, device, task_gen, all_imgs, all_colours[test_colours], test_shapes)if __name__ == '__main__':	main()
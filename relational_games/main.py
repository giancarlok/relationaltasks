import argparseimport osimport sysimport timeimport numpy as npfrom PIL import Imageimport torchimport torchvisionimport torch.nn as nnimport torch.optim as optimfrom torch.utils.data import Dataset, DataLoaderimport torch.nn.functional as F# Prevent python from saving out .pyc filessys.dont_write_bytecode = True# Add models and tasks to pathsys.path.insert(0, './models')sys.path.insert(0, './tasks')# Logging utilityfrom util import log# Method for creating directory if it doesn't exist yetdef check_path(path):	if not os.path.exists(path):		os.mkdir(path)def restructure_images(images):	img = torch.Tensor(images).float().permute(0, 3, 1, 2)	#print(img.shape)	#print("huh")	#img = img / 255.	# print("huh2")	# bsz = img.shape[0]	# print("huh2.1")	# img = img.reshape(bsz, 3, 3, 12, 3, 12).permute(0, 2, 4, 1, 3, 5)	# print("huh2.2")	# img = img.reshape(bsz, 9, 3, 12, 12)	# print("huh3")	return imgclass seq_dataset(Dataset):	def __init__(self, dset, args):		self.seq_ind = dset['seq_ind']		self.y = dset['y']		self.len = self.seq_ind.shape[0]	def __len__(self):		return self.len	def __getitem__(self, idx):		seq_ind = self.seq_ind[idx]		y = self.y[idx]		return seq_ind, ydef train(args, model, device, optimizer, iter, x_train, y_train):	# Create file for saving training progress	check_path('./results/')	train_prog_dir = './results/train_prog/'	check_path(train_prog_dir)	if args.hard:		task_dir = train_prog_dir + args.task + '_hard/'	elif args.tricky:		task_dir = train_prog_dir + args.task + '_tricky'+ str(args.sampling_weight)+'/'	elif args.colour_tested:		task_dir = train_prog_dir + args.task + '_colour_tested' + '/'	elif args.shape_tested:		task_dir = train_prog_dir + args.task + '_shape_tested' + '/'	else:		task_dir = train_prog_dir + args.task_name + '/'	check_path(task_dir)	model_dir = task_dir + args.model_name + '/'	check_path(model_dir)	run_dir = model_dir + 'run' + args.run + '/'	check_path(run_dir)	# Set to training mode 	model.train()	# Iterate over batches	# Batch start time	start_time = time.time()	#print("seq_ind", seq_ind.shape)	# Use sequence indices to slice corresponding images	x_seq = torch.Tensor(x_train)	#x_seq = x_seq[:,:,0]	y = torch.Tensor(y_train).long()	#print("x_seq", x_seq.shape)	# Load data to device	x_seq = x_seq.to(device)	y = y.to(device)	# Zero out gradients for optimizer	optimizer.zero_grad()	# Run model	if "_l1" in args.model_name:		y_pred_linear, y_pred, R_save, l1_penalty = model(x_seq, device)		loss_fn = nn.CrossEntropyLoss()		loss = loss_fn(y_pred_linear, y)+ args.l1_lambda*l1_penalty	elif 'MNM' in args.model_name:		y_pred_linear, y_pred, const_loss, R_save = model(x_seq, device)		loss_fn = nn.CrossEntropyLoss()		loss = loss_fn(y_pred_linear, y)		loss += const_loss	elif args.l1_reg:		y_pred_linear, y_pred, R_save = model(x_seq, device)		loss_fn = nn.CrossEntropyLoss()		l1_penalty = torch.mean(torch.norm(model.shape_encoder.conv1.weight, p=1, dim=(0, 2, 3))[3:])		loss = loss_fn(y_pred_linear, y)+ args.l1_lambda*l1_penalty	elif args.l2_reg:		y_pred_linear, y_pred, R_save = model(x_seq, device)		loss_fn = nn.CrossEntropyLoss()		l2_penalty = torch.mean(torch.norm(model.shape_encoder.conv1.weight, p=2, dim=(0, 2, 3))[3:])		loss = loss_fn(y_pred_linear, y) + args.l2_lambda * l2_penalty	else:		y_pred_linear, y_pred, R_save = model(x_seq, device)		loss_fn = nn.CrossEntropyLoss()		loss = loss_fn(y_pred_linear, y)	# Update model	loss.backward()	# if iter % 100 == 0:	# 	#print("CHANNEL NORMS:", torch.norm(model.shape_encoder.conv1.weight.grad, p=2, dim=(0, 2, 3)))	# # 	#print("Max:", torch.max(model.shape_encoder.conv1.weight.grad, dim=(0, 2, 3)))	# 	print(model.shape_encoder.conv1.weight.grad)	# 	print("CHANNEL GRAD NORMS:", torch.norm(model.shape_encoder.conv1.weight.grad, p=2, dim=(0, 2, 3)))	# 	print("CHANNEL WEIGHT NORMS:", torch.norm(model.shape_encoder.conv1.weight, p=2, dim=(0, 2, 3)))	optimizer.step()	# Batch duration	end_time = time.time()	batch_dur = end_time - start_time	# Report prgoress	acc = torch.eq(y_pred, y).float().mean().item() * 100.0	if iter % 10 == 0:		# Report		# print("=======================================================")		# print("erroneously diff",int((y_pred-y>0).sum()), " || erroneously same" ,int((y_pred-y<0).sum()), " || correct",int((y_pred-y==0).sum()) ,"out of total ",len(y_pred))		# print("=======================================================")		# print("DIFF: ", int(y.sum()), " || SAME: ", int(len(y)-y.sum()))		# print("=======================================================")		train_prog_fname = run_dir + 'iter_' + str(iter) + '.txt'		train_prog_f = open(train_prog_fname, 'w')		train_prog_f.write('batch loss acc\n')		log.info('[Iter: ' + str(iter) + '] ' + \				 '[Loss = ' + '{:.4f}'.format(loss.item()) + '] ' + \				 '[Accuracy = ' + '{:.2f}'.format(acc) + '] ' + \				 '[' + '{:.3f}'.format(batch_dur) + ' sec/batch]')		# Save progress to file		train_prog_f.write(str(iter) + ' ' +\						   '{:.4f}'.format(loss.item()) + ' ' + \						   '{:.2f}'.format(acc) + '\n')		train_prog_f.close()def test(args, model, device, task_gen, test_images1, test_labels1, test_images2, test_labels2):	log.info('Evaluating on test set...')	# Set to eval mode	model.eval()	# Iterate over batches	all_acc1 = []	all_loss1 = []	all_acc2 = []	all_loss2 = []	with torch.no_grad():		for batch_idx in range(1000):			# Use sequence indices to slice corresponding images			x_test1, y_test1 = task_gen.get_sample(args.train_batch_size, images = test_images1, labels = test_labels1)			x_test2, y_test2 = task_gen.get_sample(args.train_batch_size, images = test_images2, labels = test_labels2)			# Load data to device			x_seq1 = torch.Tensor(x_test1)			x_seq2 = torch.Tensor(x_test2)			#x_seq = x_seq[:, :, 0]			y1 = torch.Tensor(y_test1).long()			y2 = torch.Tensor(y_test2).long()			x_seq1 = x_seq1.to(device)			x_seq2 = x_seq2.to(device)			y1 = y1.to(device)			y2 = y2.to(device)			# Run model			if "_l1" in args.model_name:				y_pred_linear1, y_pred1, R_save1, l1_penalty1 = model(x_seq1, device)				y_pred_linear2, y_pred2, R_save2, l1_penalty2 = model(x_seq2, device)			elif 'MNM' in args.model_name:				y_pred_linear1, y_pred1, const_loss1, R_save1 = model(x_seq1, device)				y_pred_linear2, y_pred2, const_loss2, R_save2 = model(x_seq2, device)			else:				y_pred_linear1, y_pred1, R_save1 = model(x_seq1, device)				y_pred_linear2, y_pred2, R_save2 = model(x_seq2, device)			#print(R_save.shape)			if args.saving_image:				img_dir =  './matrix_images/'				check_path(img_dir)				img_task_dir = img_dir + args.task + '/'				check_path(img_task_dir)				img_gen_dir = img_task_dir + 'm' + str(args.m_holdout) + '/'				check_path(img_gen_dir)				img_model_dir = img_gen_dir + "/" +args.model_name+ "/"				check_path(img_model_dir)				# print(y.shape)				# print("hello", y_pred.shape)				error_image = torch.abs(y-y_pred).view(y.shape[0], 1,1,1)*torch.ones_like(x_seq[0])				print(y.shape)				print(y.type)				print(x_seq[0])				y_img = torch.abs(y).view(y.shape[0], 1,1,1)*torch.ones_like(x_seq[0])				print(y_img.shape)				print(y_img.type)				y_pred_img = torch.abs(y).view(y.shape[0], 1, 1, 1) * torch.ones_like(x_seq[0])				torchvision.utils.save_image(y_img, img_model_dir+"y_img.png")				torchvision.utils.save_image(y_pred_img, img_model_dir+"y_pred_img.png")				torchvision.utils.save_image(error_image, img_model_dir+"error.png")				# print("x_Seq", x_seq.shape)				# print("shape ", x_seq.shape[-3:])				# print(R_save.shape)				if args.task == "same_diff":					icons = torch.cat([x_seq[:,0].unsqueeze(1), x_seq[:,1].unsqueeze(1)], dim=-1)				elif args.task == "RMTS":					row1 = torch.cat([x_seq[:,0].unsqueeze(1), x_seq[:,1].unsqueeze(1), torch.zeros(x_seq[:,0].shape).unsqueeze(1), torch.zeros(x_seq[:,0].shape).unsqueeze(1)], dim=-1)					row2 = torch.cat([x_seq[:,2].unsqueeze(1), x_seq[:,3].unsqueeze(1), x_seq[:,4].unsqueeze(1), x_seq[:,5].unsqueeze(1)], dim=-1)					print(row1.shape)					print(row2.shape)					icons = torch.cat([row1, row2], dim=-2)				else:					icons = x_seq[:, 0].unsqueeze(1)					for k in range(1, 9):						icons = torch.cat([icons, x_seq[:, k].unsqueeze(1)], dim=-1)				torchvision.utils.save_image(icons, img_model_dir+"image.png", padding = 8)				if R_save is not None:					R_save = nn.Upsample(scale_factor = x_seq.shape[-2:])(R_save.unsqueeze(1))					torchvision.utils.save_image(R_save, img_model_dir+"matrix.png", padding = 16)			# Loss			loss_fn = nn.CrossEntropyLoss()			loss1 = loss_fn(y_pred_linear1, y1)			loss2 = loss_fn(y_pred_linear2, y2)			if 'MNM' in args.model_name:				loss1 += const_loss1				loss2 += const_loss2			all_loss1.append(loss1.item())			all_loss2.append(loss2.item())			# Accuracy			acc1 = torch.eq(y_pred1, y1).float().mean().item() * 100.0			acc2 = torch.eq(y_pred2, y2).float().mean().item() * 100.0			all_acc1.append(acc1)			all_acc2.append(acc2)		# Report progress	# Report overall test performance	avg_loss1 = np.mean(all_loss1)	avg_loss2 = np.mean(all_loss2)	avg_acc1 = np.mean(all_acc1)	avg_acc2 = np.mean(all_acc2)	log.info('[Summary hexos] ' + \			 '[Loss = ' + '{:.4f}'.format(avg_loss1) + '] ' + \			 '[Accuracy = ' + '{:.2f}'.format(avg_acc1) + ']')	if "shape" in args.task_name:		log.info('[Summary pentos valid] ' + \				 '[Loss = ' + '{:.4f}'.format(avg_loss2) + '] ' + \				 '[Accuracy = ' + '{:.2f}'.format(avg_acc2) + ']')	else:		log.info('[Summary stripes] ' + \				'[Loss = ' + '{:.4f}'.format(avg_loss2) + '] ' + \				'[Accuracy = ' + '{:.2f}'.format(avg_acc2) + ']')	# Save performance	test_dir = './results/test/'	check_path(test_dir)	if args.hard:		task_dir = test_dir + args.task + '_hard/'	elif args.tricky:		task_dir = test_dir + args.task +'_tricky' + str(args.sampling_weight) + '/'	elif args.colour_tested:		task_dir = test_dir + args.task + '_colour_tested' + '/'	elif args.shape_tested:		task_dir = test_dir + args.task + '_shape_tested' + '/'	else:		task_dir = test_dir + args.task_name + '/'	check_path(task_dir)	model_dir = task_dir + args.model_name + '/'	check_path(model_dir)	# saving hexominoes test results	test_fname = model_dir + 'run' + args.run + 'hexos.txt'	test_f = open(test_fname, 'w')	test_f.write('loss acc\n')	test_f.write('{:.4f}'.format(avg_loss1) + ' ' + \				 '{:.2f}'.format(avg_acc1))	test_f.close()	#saving stripes test results	if "shape" in args.task_name:		test_fname = model_dir + 'run' + args.run + 'pentos_valid.txt'	else:		test_fname = model_dir + 'run' + args.run + 'stripes.txt'	test_f = open(test_fname, 'w')	test_f.write('loss acc\n')	test_f.write('{:.4f}'.format(avg_loss2) + ' ' + \				 '{:.2f}'.format(avg_acc2))	test_f.close()def simple_test(args, model, device, task_gen, test_images1, test_labels1):	log.info('Evaluating on test set...')	# Set to eval mode	model.eval()	# Iterate over batches	all_acc1 = []	all_loss1 = []	with torch.no_grad():		for batch_idx in range(1000):			# Use sequence indices to slice corresponding images			x_test1, y_test1 = task_gen.get_sample(args.train_batch_size, images = test_images1, labels = test_labels1)			# Load data to device			x_seq1 = torch.Tensor(x_test1)			#x_seq = x_seq[:, :, 0]			y1 = torch.Tensor(y_test1).long()			x_seq1 = x_seq1.to(device)			y1 = y1.to(device)			# Run model			if "_l1" in args.model_name:				y_pred_linear1, y_pred1, R_save1, l1_penalty1 = model(x_seq1, device)			elif 'MNM' in args.model_name:				y_pred_linear1, y_pred1, const_loss1, R_save1 = model(x_seq1, device)			else:				y_pred_linear1, y_pred1, R_save1 = model(x_seq1, device)			#print(R_save.shape)			if args.saving_image:				img_dir =  './matrix_images/'				check_path(img_dir)				img_task_dir = img_dir + args.task + '/'				check_path(img_task_dir)				img_gen_dir = img_task_dir + 'm' + str(args.m_holdout) + '/'				check_path(img_gen_dir)				img_model_dir = img_gen_dir + "/" +args.model_name+ "/"				check_path(img_model_dir)				# print(y.shape)				# print("hello", y_pred.shape)				error_image = torch.abs(y-y_pred).view(y.shape[0], 1,1,1)*torch.ones_like(x_seq[0])				print(y.shape)				print(y.type)				print(x_seq[0])				y_img = torch.abs(y).view(y.shape[0], 1,1,1)*torch.ones_like(x_seq[0])				print(y_img.shape)				print(y_img.type)				y_pred_img = torch.abs(y).view(y.shape[0], 1, 1, 1) * torch.ones_like(x_seq[0])				torchvision.utils.save_image(y_img, img_model_dir+"y_img.png")				torchvision.utils.save_image(y_pred_img, img_model_dir+"y_pred_img.png")				torchvision.utils.save_image(error_image, img_model_dir+"error.png")				# print("x_Seq", x_seq.shape)				# print("shape ", x_seq.shape[-3:])				# print(R_save.shape)				if args.task == "same_diff":					icons = torch.cat([x_seq[:,0].unsqueeze(1), x_seq[:,1].unsqueeze(1)], dim=-1)				elif args.task == "RMTS":					row1 = torch.cat([x_seq[:,0].unsqueeze(1), x_seq[:,1].unsqueeze(1), torch.zeros(x_seq[:,0].shape).unsqueeze(1), torch.zeros(x_seq[:,0].shape).unsqueeze(1)], dim=-1)					row2 = torch.cat([x_seq[:,2].unsqueeze(1), x_seq[:,3].unsqueeze(1), x_seq[:,4].unsqueeze(1), x_seq[:,5].unsqueeze(1)], dim=-1)					print(row1.shape)					print(row2.shape)					icons = torch.cat([row1, row2], dim=-2)				else:					icons = x_seq[:, 0].unsqueeze(1)					for k in range(1, 9):						icons = torch.cat([icons, x_seq[:, k].unsqueeze(1)], dim=-1)				torchvision.utils.save_image(icons, img_model_dir+"image.png", padding = 8)				if R_save is not None:					R_save = nn.Upsample(scale_factor = x_seq.shape[-2:])(R_save.unsqueeze(1))					torchvision.utils.save_image(R_save, img_model_dir+"matrix.png", padding = 16)			# Loss			loss_fn = nn.CrossEntropyLoss()			loss1 = loss_fn(y_pred_linear1, y1)			if 'MNM' in args.model_name:				loss1 += const_loss1							all_loss1.append(loss1.item())			# Accuracy			acc1 = torch.eq(y_pred1, y1).float().mean().item() * 100.0			all_acc1.append(acc1)		# Report progress	# Report overall test performance	avg_loss1 = np.mean(all_loss1)	avg_acc1 = np.mean(all_acc1)	log.info('[Summary hexos] ' + \			 '[Loss = ' + '{:.4f}'.format(avg_loss1) + '] ' + \			 '[Accuracy = ' + '{:.2f}'.format(avg_acc1) + ']')	# Save performance	test_dir = './results/test/'	check_path(test_dir)	if args.hard:		task_dir = test_dir + args.task + '_hard/'	elif args.tricky:		task_dir = test_dir + args.task +'_tricky' + str(args.sampling_weight) + '/'	elif args.colour_tested:		task_dir = test_dir + args.task + '_colour_tested' + '/'	elif args.shape_tested:		task_dir = test_dir + args.task + '_shape_tested' + '/'	else:		task_dir = test_dir + args.task_name + '/'	check_path(task_dir)	model_dir = task_dir + args.model_name + '/'	check_path(model_dir)	# saving hexominoes test results	test_fname = model_dir + 'run' + args.run + 'hexos.txt'	test_f = open(test_fname, 'w')	test_f.write('loss acc\n')	test_f.write('{:.4f}'.format(avg_loss1) + ' ' + \				 '{:.2f}'.format(avg_acc1))	test_f.close()def test_old(args, model, device, task_gen, all_imgs, all_colours, test_shapes):	log.info('Evaluating on test set...')	# Set to eval mode	model.eval()	# Iterate over batches	all_acc = []	all_loss = []	with torch.no_grad():		for batch_idx in range(1000):			# Use sequence indices to slice corresponding images			prob = [0.5,0.5]			if args.hard:				x_train, y_train = task_gen.get_hard_sample(args.test_batch_size, prob, all_imgs[test_shapes])			elif args.task == "mini":				x_train, y_train = task_gen.get_sample(args.train_batch_size, args.task_name, set_name="pentos")			elif args.tricky:				x_train, y_train = task_gen.get_tricky_sample(args.test_batch_size, prob, all_imgs[test_shapes], all_colours, 1-args.sampling_weight)			elif args.colour_tested:				#print("colour_tested")				x_train, y_train = task_gen.get_coloured_sample(args.test_batch_size, prob, all_imgs[test_shapes], all_colours)			elif args.shape_tested:				#print("colour_tested")				x_train, y_train = task_gen.get_shapes_sample(args.test_batch_size, prob, all_imgs[test_shapes], all_colours)			elif "identity_rules4_" in args.task or "_hard" in args.task:				x_train, y_train = task_gen.get_test_sample(args.test_batch_size, prob, all_imgs[test_shapes],															  all_colours)			else:				x_train, y_train = task_gen.get_sample(args.test_batch_size, prob, all_imgs[test_shapes], all_colours)			# Load data to device			x_seq = torch.Tensor(x_train)			#x_seq = x_seq[:, :, 0]			y = torch.Tensor(y_train).long()			x_seq = x_seq.to(device)			y = y.to(device)			# Run model			if "_l1" in args.model_name:				y_pred_linear, y_pred, R_save, l1_penalty = model(x_seq, device)			else:				y_pred_linear, y_pred, R_save = model(x_seq, device)			#print(R_save.shape)			if args.saving_image:				img_dir =  './matrix_images/'				check_path(img_dir)				img_task_dir = img_dir + args.task + '/'				check_path(img_task_dir)				img_gen_dir = img_task_dir + 'm' + str(args.m_holdout) + '/'				check_path(img_gen_dir)				img_model_dir = img_gen_dir + "/" +args.model_name+ "/"				check_path(img_model_dir)				# print(y.shape)				# print("hello", y_pred.shape)				error_image = torch.abs(y-y_pred).view(y.shape[0], 1,1,1)*torch.ones_like(x_seq[0])				print(y.shape)				print(y.type)				print(x_seq[0])				y_img = torch.abs(y).view(y.shape[0], 1,1,1)*torch.ones_like(x_seq[0])				print(y_img.shape)				print(y_img.type)				y_pred_img = torch.abs(y).view(y.shape[0], 1, 1, 1) * torch.ones_like(x_seq[0])				torchvision.utils.save_image(y_img, img_model_dir+"y_img.png")				torchvision.utils.save_image(y_pred_img, img_model_dir+"y_pred_img.png")				torchvision.utils.save_image(error_image, img_model_dir+"error.png")				# print("x_Seq", x_seq.shape)				# print("shape ", x_seq.shape[-3:])				# print(R_save.shape)				if args.task == "same_diff":					icons = torch.cat([x_seq[:,0].unsqueeze(1), x_seq[:,1].unsqueeze(1)], dim=-1)				elif args.task == "RMTS":					row1 = torch.cat([x_seq[:,0].unsqueeze(1), x_seq[:,1].unsqueeze(1), torch.zeros(x_seq[:,0].shape).unsqueeze(1), torch.zeros(x_seq[:,0].shape).unsqueeze(1)], dim=-1)					row2 = torch.cat([x_seq[:,2].unsqueeze(1), x_seq[:,3].unsqueeze(1), x_seq[:,4].unsqueeze(1), x_seq[:,5].unsqueeze(1)], dim=-1)					print(row1.shape)					print(row2.shape)					icons = torch.cat([row1, row2], dim=-2)				else:					icons = x_seq[:, 0].unsqueeze(1)					for k in range(1, 9):						icons = torch.cat([icons, x_seq[:, k].unsqueeze(1)], dim=-1)				torchvision.utils.save_image(icons, img_model_dir+"image.png", padding = 8)				if R_save is not None:					R_save = nn.Upsample(scale_factor = x_seq.shape[-2:])(R_save.unsqueeze(1))					torchvision.utils.save_image(R_save, img_model_dir+"matrix.png", padding = 16)			# Loss			loss_fn = nn.CrossEntropyLoss()			loss = loss_fn(y_pred_linear, y)			all_loss.append(loss.item())			# Accuracy			acc = torch.eq(y_pred, y).float().mean().item() * 100.0			all_acc.append(acc)		# Report progress	# Report overall test performance	avg_loss = np.mean(all_loss)	avg_acc = np.mean(all_acc)	log.info('[Summary] ' + \			 '[Loss = ' + '{:.4f}'.format(avg_loss) + '] ' + \			 '[Accuracy = ' + '{:.2f}'.format(avg_acc) + ']')	# Save performance	test_dir = './results/test/'	check_path(test_dir)	if args.hard:		task_dir = test_dir + args.task + '_hard/'	elif args.tricky:		task_dir = test_dir + args.task +'_tricky' + str(args.sampling_weight) + '/'	elif args.colour_tested:		task_dir = test_dir + args.task + '_colour_tested' + '/'	elif args.shape_tested:		task_dir = test_dir + args.task + '_shape_tested' + '/'	else:		task_dir = test_dir + args.task + '/'	check_path(task_dir)	shapes_gen_dir = task_dir + 'n' + str(args.n_shapes) + '/'	check_path(shapes_gen_dir)	gen_dir = shapes_gen_dir + 'm' + str(args.m_holdout) + '/'	check_path(gen_dir)	model_dir = gen_dir + args.model_name + '/'	check_path(model_dir)	test_fname = model_dir + 'run' + args.run + '.txt'	test_f = open(test_fname, 'w')	test_f.write('loss acc\n')	test_f.write('{:.4f}'.format(avg_loss) + ' ' + \				 '{:.2f}'.format(avg_acc))	test_f.close()def main():	# Settings	parser = argparse.ArgumentParser()	# Model settings	parser.add_argument('--model_name', type=str, default='ESBN', help="{'ESBN', 'Transformer', 'NTM', 'LSTM', 'PrediNet', 'RN', 'MNM', 'TRN', 'ESBN_confidence_ablation', 'ESBN_default_memory', 'tsf', 'rule_tsf', 'ni_tsf'}")	parser.add_argument('--task_name', type=str, default='between',						help="{'ESBN', 'Transformer', 'NTM', 'LSTM', 'PrediNet', 'RN', 'MNM', 'TRN', 'ESBN_confidence_ablation', 'ESBN_default_memory', 'tsf', 'rule_tsf', 'ni_tsf'}")	parser.add_argument('--norm_type', type=str, default='contextnorm', help="{'nonorm', 'contextnorm', 'tasksegmented_contextnorm'}")	parser.add_argument('--encoder', type=str, default='conv', help="{'conv', 'mlp', 'rand'}")	parser.add_argument('--l1_lambda', type=float, default=0.001)	parser.add_argument('--l2_lambda', type=float, default=0.001)	# Transformer Based Model Settings	parser.add_argument('--heads', type=int, default=8)	parser.add_argument('--rules', type=int, default=1)	parser.add_argument('--layers', type=int, default=1)	parser.add_argument('--freeze_encoder', action='store_true', default=False)	parser.add_argument('--norm_before', action='store_true', default=False)	parser.add_argument('--l1_reg', action='store_true', default=False)	parser.add_argument('--l2_reg', action='store_true', default=False)	parser.add_argument('--residual', action='store_true', default=False)	parser.add_argument('--sqrt', action='store_true', default=False)	parser.add_argument('--gumbel', action='store_true', default=False)	parser.add_argument('--colour_tested', action='store_true', default=False)	parser.add_argument('--shape_tested', action='store_true', default=False)	parser.add_argument('--normalized', action='store_true', default=False)	parser.add_argument('--detached', action='store_true', default=False)	parser.add_argument('--saving_image', action='store_true', default=False)	parser.add_argument('--no_adding', action='store_true', default=False)	parser.add_argument('--no_positional', action='store_true', default=False)	parser.add_argument('--hard', action='store_true', default=False)	parser.add_argument('--tricky', action='store_true', default=False)	parser.add_argument('--sampling_weight', type=float, default=0.1)	parser.add_argument('--reduced', action='store_true', default=False)	parser.add_argument('--use_sigmoid', action='store_true', default=False)	parser.add_argument('--use_rnn', action='store_true', default=False)	parser.add_argument('--no_masking', action='store_true', default=False)	parser.add_argument('--conf_abs', action='store_true', default=False)	parser.add_argument('--conf_sigmoid', action='store_true', default=False)	parser.add_argument('--concat_after', action='store_true', default=False)	parser.add_argument('--key_dim', type=int, default=256,						help="dimension of abstract keys")	parser.add_argument('--query_dim', type=int, default=8,						help="dimension of abstract keys")	parser.add_argument('--value_dim', type=int, default=256,						help="dimension of abstract keys")	parser.add_argument('--pos_dim', type=int, default=8,						help="dimension of abstract keys")	parser.add_argument('--tsf_dim', type=int, default=512,						help="dimension of abstract keys")	parser.add_argument('--selfattention', action='store_true', default=False)	parser.add_argument('--separate', action='store_true', default=False)	# Task settings	parser.add_argument('--task', type=str, default='relational', help="{'relational'}")	parser.add_argument('--train_gen_method', type=str, default='full_space', help="{'full_space', 'subsample'}")	parser.add_argument('--test_gen_method', type=str, default='full_space', help="{'full_space', 'subsample'}")	parser.add_argument('--n_colours', type=int, default=100, help="n = total number of colours available for training and testing")	parser.add_argument('--n_shapes', type=int, default=100, help="n = total number of shapes available for training and testing")	parser.add_argument('--m_holdout', type=int, default=0, help="m = number of objects (out of n) withheld during training")	parser.add_argument('--c_holdout', type=int, default=0, help="m = number of objects (out of n) withheld during training")	# Training settings	parser.add_argument('--train_batch_size', type=int, default=32)	parser.add_argument('--train_set_size', type=int, default=10000)	parser.add_argument('--train_proportion', type=float, default=0.95)	parser.add_argument('--lr', type=float, default=5e-4)	parser.add_argument('--iterations', type=int, default=5000)	parser.add_argument('--log_interval', type=int, default=10)	# Test settings	parser.add_argument('--test_batch_size', type=int, default=1000)	parser.add_argument('--test_set_size', type=int, default=10000)	# Device settings	parser.add_argument('--no-cuda', action='store_true', default=False)	parser.add_argument('--device', type=int, default=0)	# Run number	parser.add_argument('--run', type=str, default='1')	args = parser.parse_args()	# TSF parameters	args.key_dim = args.tsf_dim	args.value_dim = args.tsf_dim	if "CoRelNet" in args.model_name:		args.selfattention = True		args.reduced = True		args.no_adding = True	if "CoRelNet_qtsf" in args.model_name:		args.sqrt = True		args.residual = True	# Set up cuda	use_cuda = not args.no_cuda and torch.cuda.is_available()	device = torch.device("cuda:" + str(args.device) if use_cuda else "cpu")	kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}	if "shape" in args.task_name:		loader_train = np.load('npz_files/{}_{}.npz'.format(args.task_name, "pentos"), 'rb')		loader_test1 = np.load('npz_files/{}_{}.npz'.format(args.task_name, "hexos"), 'rb')		loader_test2 = np.load('npz_files/{}_{}.npz'.format(args.task_name, "pentos_valid"), 'rb')		train_images = restructure_images(loader_train["images"])		train_labels = loader_train["labels"]		test_images1 = restructure_images(loader_test1["images"])		test_labels1 = loader_test1["labels"]		test_images2 = restructure_images(loader_test2["images"])		test_labels2 = loader_test2["labels"]	elif "leftof_dataset" in args.task_name:		loader_train = np.load('npz_files/{}_{}.npz'.format(args.task_name, "pentos"), 'rb')		loader_test1 = np.load('npz_files/{}_{}.npz'.format(args.task_name, "hexos"), 'rb')		train_images = restructure_images(loader_train["images"])		train_labels = loader_train["labels"]		test_images1 = restructure_images(loader_test1["images"])		test_labels1 = loader_test1["labels"]	else:		loader_train = np.load('npz_files/{}_{}.npz'.format(args.task_name, "pentos"), 'rb')		loader_test1 = np.load('npz_files/{}_{}.npz'.format(args.task_name, "hexos"), 'rb')		loader_test2 = np.load('npz_files/{}_{}.npz'.format(args.task_name, "stripes"), 'rb')		train_images = restructure_images(loader_train["images"])		train_labels = loader_train["labels"]		test_images1 = restructure_images(loader_test1["images"])		test_labels1 = loader_test1["labels"]		test_images2 = restructure_images(loader_test2["images"])		test_labels2 = loader_test2["labels"]	# Generate training and test sets	task_gen = __import__(args.task)	log.info('Generating task: ' + args.task + '...')	print("args task ", args.task)	print("task_gen", task_gen)	task_gen.y_dim = len(set(train_labels[:, 0]))	print("y_dim", task_gen.y_dim)	model_class = __import__(args.model_name)	model = model_class.Model(task_gen, args).to(device)	# Append relevant hyperparameter values to model name	if 'tsf' in args.model_name:		args.model_name = args.model_name + '-heads-' + str(args.heads) + '-layers-' + str(args.layers) + '-dim-' + str(args.tsf_dim)+ '-pos_dim-' + str(args.pos_dim)		if 'qtsf' in args.model_name:			args.model_name = args.model_name +'-qdim-' + str(args.query_dim)	elif args.model_name == 'rule_tsf' or args.model_name == 'ni_tsf':		args.model_name = args.model_name + '-heads-' + str(args.heads) + '-rules-' + str(args.rules) + '-layers-' + str(args.layers)	if '_l1' in args.model_name:		args.model_name = args.model_name + '-lambda-' + str(args.l1_lambda)	if args.separate and 'tsf' in args.model_name:		args.model_name = args.model_name + '-separate'	if args.gumbel and ('rule' in args.model_name or 'ni' in args.model_name):		args.model_name = args.model_name + '-gumbel'	if args.selfattention:		args.model_name = args.model_name + '-selfattention'		if args.no_adding:			args.model_name = args.model_name + '-noadding'		if args.no_masking:			args.model_name = args.model_name + '-nomasking'		elif args.reduced:			args.model_name = args.model_name + '-reduced'	if args.normalized:		args.model_name = args.model_name + '-normalized'		if args.detached:			args.model_name = args.model_name + '-detached'	if args.no_positional:		args.model_name = args.model_name + '-no_positional'	if args.residual:		args.model_name = args.model_name + '-residual'	if args.sqrt:		args.model_name = args.model_name + '-sqrt'	if args.norm_before:		args.model_name = args.model_name + '-norm_before'	if args.freeze_encoder:		args.model_name = args.model_name + '-freeze_encoder'	args.model_name = args.model_name + '_' + args.norm_type + '_lr' + str(args.lr)	# Create optimizer	log.info('Setting up optimizer...')	optimizer = optim.Adam(model.parameters(), lr=args.lr)	# Train	log.info('Training begins...')	for iter in range(1, args.iterations + 1):		# Training loop		prob = [0.5, 0.5]		if args.tricky:			x_train, y_train = task_gen.get_tricky_sample(args.train_batch_size, prob, all_imgs[train_shapes, :, :, :], all_colours[train_colours, :, :, :], args.sampling_weight)		elif args.task == "relational":			x_train, y_train = task_gen.get_sample(args.train_batch_size, images=train_images, labels=train_labels)		else:			x_train, y_train = task_gen.get_sample(args.train_batch_size, prob, all_imgs[train_shapes,:,:,:], all_colours[train_colours, :, :, :])		train(args, model, device, optimizer, iter, x_train, y_train)	# Test model	if "leftof_datatset" in args.task_name:		simple_test(args, model, device, task_gen, test_images1, test_labels1)	else:		test(args, model, device, task_gen, test_images1, test_labels1, test_images2, test_labels2)if __name__ == '__main__':	main()